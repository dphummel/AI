{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9413082,"sourceType":"datasetVersion","datasetId":5716422}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/davidphummel/computer-vision-is-it-a-dog-or-a-cat?scriptVersionId=196908614\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Computer Vision - Is it a dog or a cat?","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"This is the first Juypter notebook I created while reading chapter 1 of the Fastai course called [Practical Deep Learning](https://course.fast.ai).  Practical Deep Learning is a free course designed for people who have some coding experience and want to learn how to apply deep learning and maching learning to practical problems.  \n\nI have found an understanding of how to program in Python is a requirement to complete this course along with a good understanding of the mathematical concepts.  I have spent some time refershing my memory of the NumPy package using the book [NumPy for Data Analysis](https://wesmckinney.com/book/numpy-basics) by Wes McKinney.  The NumPy pachage is used in the course to load and clean data along with building the models.  I have also found the need to refresh my memory of some of mathmatical concepts included in deep learning including gradient descent.  I really recommend the videos produced by [StatQuest](https://statquest.org/) on [gradient descent](https://youtu.be/sDv4f4s2SB8?si=SZjknb9ca-nl18ie) and others related to statistics and machine learning.  Josh Starmer created StatQuest to attempt to explain statistics to his former co-wokers.  His vidoes are simple easy to understand, and engaging! \n\nThis Juypter notebook is a copy of Jeremy Howard's notebook called [Is it a bird? Creating a model from your own data](https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data).  I modified Jeremy's notebook to determine if an image is a dog or a cat.  I have two portugese water dogs and 1 three legged cat, so I thought it would be fun to focus on them.  The objective of the notebook is to create and train a model to determine if an image is a dog or cat.","metadata":{}},{"cell_type":"code","source":"# It's a good idea to ensure you're running the latest version of any libraries you need.\n# `!pip install -Uqq <libraries>` upgrades to the latest version of <libraries>\n# You can safely ignore any warnings or errors pip spits out about running as root or incompatibilities\n#import os\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle:\n    !pip install -Uqq fastai fastbook","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-16T16:21:48.768291Z","iopub.execute_input":"2024-09-16T16:21:48.768628Z","iopub.status.idle":"2024-09-16T16:22:10.38122Z","shell.execute_reply.started":"2024-09-16T16:21:48.768595Z","shell.execute_reply":"2024-09-16T16:22:10.380303Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nexplainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\ntensorflow 2.6.2 requires numpy~=1.19.2, but you have numpy 1.20.3 which is incompatible.\ntensorflow 2.6.2 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\ntensorflow 2.6.2 requires wrapt~=1.12.1, but you have wrapt 1.13.3 which is incompatible.\ntensorflow-transform 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\ntensorflow-transform 1.5.0 requires numpy<1.20,>=1.16, but you have numpy 1.20.3 which is incompatible.\ntensorflow-transform 1.5.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\ntensorflow-transform 1.5.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.2, but you have tensorflow 2.6.2 which is incompatible.\ntensorflow-serving-api 2.7.0 requires tensorflow<3,>=2.7.0, but you have tensorflow 2.6.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\napache-beam 2.34.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\napache-beam 2.34.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\napache-beam 2.34.0 requires pyarrow<6.0.0,>=0.15.1, but you have pyarrow 6.0.1 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.1.2 requires botocore<1.23.25,>=1.23.24, but you have botocore 1.24.20 which is incompatible.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The basic steps we'll take are:\n\n1. Use DuckDuckGo to find images of dogs and cats on the Internet.\n2. Fine-tune a pretrained neural network to recognise these two animals.\n3. Try running this model on set of pictures and see if it works.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Download images of cats and dogs","metadata":{}},{"cell_type":"markdown","source":"Fastcore uses this flexibility to add to Python features inspired by other languages like multiple dispatch from Julia, mixins from Ruby, and currying, binding, and more from Haskell. It also adds some “missing features” and clean up some rough edges in the Python standard library, such as simplifying parallel processing, and bringing ideas from NumPy over to Python’s list type.\n\nLet's start out by defining a function to search the Internet using DuckDuckGo for a term (e.g., \"dog\") and return a set of URLs to images of the term.","metadata":{}},{"cell_type":"code","source":"from fastcore.all import *\nfrom fastbook import search_images_ddg\n\ndef search_images(term, max=30):\n  print(f\"Searching for '{term}' using DuckDuckGo\")\n  return search_images_ddg(term, max_images=max)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-16T16:22:38.661151Z","iopub.execute_input":"2024-09-16T16:22:38.662002Z","iopub.status.idle":"2024-09-16T16:22:38.695642Z","shell.execute_reply.started":"2024-09-16T16:22:38.661958Z","shell.execute_reply":"2024-09-16T16:22:38.694537Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3990532614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msearch_images_ddg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Searching for '{term}' using DuckDuckGo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastbook/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.0.29\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkgutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/vision/all.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/vision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/vision/models/xresnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# %% ../../../nbs/11_vision.models.xresnet.ipynb 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mtorch_basics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_basics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorch_imports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorch_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# %% ../nbs/00_torch_core.ipynb 37\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__array_eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mpatch\u001b[0;34m(f, as_prop, cls_method)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfastuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfastuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0m__iadd__\u001b[0m \u001b[0m__isub__\u001b[0m \u001b[0m__imul__\u001b[0m \u001b[0m__imatmul__\u001b[0m \u001b[0m__itruediv__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0m__ifloordiv__\u001b[0m \u001b[0m__imod__\u001b[0m \u001b[0m__ipow__\u001b[0m \u001b[0m__ilshift__\u001b[0m \u001b[0m__irshift__\u001b[0m \u001b[0m__iand__\u001b[0m \u001b[0m__ixor__\u001b[0m \u001b[0m__ior__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m \"\"\".split()\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;31m# %% ../nbs/01_basics.ipynb 311\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '__name__'"],"ename":"AttributeError","evalue":"'str' object has no attribute '__name__'","output_type":"error"}]},{"cell_type":"markdown","source":"Let's search for a dog, cat, and bird image and see what kind of result we get. I am downloading bird image because I want to see how the model reacts to a non-dog/non-cat image.  \n\nWe'll start by getting URLs using the search function.","metadata":{}},{"cell_type":"code","source":"from fastdownload import download_url\nfrom fastai.vision.all import *\nfrom PIL import Image, ImageOps\n\n# Download the image of Max (see my-family-dogs dataset)\nmax_file = \"../input/my-family-pets/Max.jpg\"\nmax_image = Image.open(max_file)\nmax_image = ImageOps.exif_transpose(max_image)\nmax_image.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:57:13.047858Z","iopub.execute_input":"2024-09-16T14:57:13.048545Z","iopub.status.idle":"2024-09-16T14:57:13.103942Z","shell.execute_reply.started":"2024-09-16T14:57:13.048506Z","shell.execute_reply":"2024-09-16T14:57:13.103269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download the first image of Lucy (see My Family Pets dataset)\nlucy_file = \"../input/my-family-pets/Lucy.jpg\"\nlucy_image = Image.open(lucy_file)\nlucy_image = ImageOps.exif_transpose(lucy_image)\nlucy_image.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:57:15.670293Z","iopub.execute_input":"2024-09-16T14:57:15.670578Z","iopub.status.idle":"2024-09-16T14:57:15.739552Z","shell.execute_reply.started":"2024-09-16T14:57:15.670547Z","shell.execute_reply":"2024-09-16T14:57:15.738846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download the second image of Lucy (see My Family Pets dataset)\nlucy_file2 = \"../input/my-family-pets/Lucy_2.jpg\"\nlucy_image2 = Image.open(lucy_file2)\nlucy_image2 = ImageOps.exif_transpose(lucy_image2)\nlucy_image2.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:57:18.520114Z","iopub.execute_input":"2024-09-16T14:57:18.520855Z","iopub.status.idle":"2024-09-16T14:57:18.566204Z","shell.execute_reply.started":"2024-09-16T14:57:18.520815Z","shell.execute_reply":"2024-09-16T14:57:18.565498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download the third image of Lucy (see My Family Pets dataset)\nlucy_file3 = \"../input/my-family-pets/Lucy_3.jpg\"\nlucy_image3 = Image.open(lucy_file3)\nlucy_image3 = ImageOps.exif_transpose(lucy_image3)\nlucy_image3.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:57:21.022045Z","iopub.execute_input":"2024-09-16T14:57:21.022339Z","iopub.status.idle":"2024-09-16T14:57:21.068743Z","shell.execute_reply.started":"2024-09-16T14:57:21.022304Z","shell.execute_reply":"2024-09-16T14:57:21.068025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download image of Chica (see My Family Pets dataset)\nchica_file = '../input/my-family-pets/Chica.jpg'\nchica_image = Image.open(chica_file)\nchica_image = ImageOps.exif_transpose(chica_image)\nchica_image.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:58:38.748959Z","iopub.execute_input":"2024-09-16T14:58:38.749741Z","iopub.status.idle":"2024-09-16T14:58:38.794296Z","shell.execute_reply.started":"2024-09-16T14:58:38.749703Z","shell.execute_reply":"2024-09-16T14:58:38.79359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The searches seem to be giving reasonable results, so let's grab a few examples dog and cat photos, and save each group of photos to a different folder.  We are also grabbing a set of images with different lighting conditions.","metadata":{}},{"cell_type":"code","source":"from time import sleep\n\nterms = 'dog','cat'\npath = Path('animals')\n\nfor term in terms:\n    dest = (path/term)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{term} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{term} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{term} shade photo'))\n    sleep(10)\n    resize_images(path/term, max_size=400, dest=path/term)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T14:58:44.728109Z","iopub.execute_input":"2024-09-16T14:58:44.728675Z","iopub.status.idle":"2024-09-16T15:00:12.774145Z","shell.execute_reply.started":"2024-09-16T14:58:44.728636Z","shell.execute_reply":"2024-09-16T15:00:12.77324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Train the model","metadata":{}},{"cell_type":"markdown","source":"Some photos might not download correctly which could cause our model training to fail, so we'll remove them:","metadata":{}},{"cell_type":"code","source":"# Find the images that can't be opened\nfailed = verify_images(get_image_files(path))\n\n# Remove the image files which can't be openend.  The map function will execute the\n# Path.unlink function over the failed images in the failed (L) object.\nfailed.map(Path.unlink)\n\nprint(f\"{len(failed)} images were removed because they could not be verified.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:00:16.733795Z","iopub.execute_input":"2024-09-16T15:00:16.734109Z","iopub.status.idle":"2024-09-16T15:00:17.086305Z","shell.execute_reply.started":"2024-09-16T15:00:16.734073Z","shell.execute_reply":"2024-09-16T15:00:17.085422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To train a model, we'll need `DataLoaders`, which is an object that contains a *training set* (the images used to create a model) and a *validation set* (the images used to check the accuracy of a model -- not used during training). In `fastai` we can create that easily using a `DataBlock`, and view sample images from it:","metadata":{}},{"cell_type":"markdown","source":"Here what each of the `DataBlock` parameters means:\n\n- ***blocks=(ImageBlock, CategoryBlock)*** - the input to our model are images and the outputs are catogries (in this case either a dog or a cat)\n\n- ***get_items=get_image_files*** - to find all the inputs to the model we run the 'get_image_files' function which results a list of all the image files in the path.\n\n- ***splitter=RandomSplitter(valid_pct=0.2, seed=42)*** - spilt the data into training and validation sets randomly using 20% of the adta for the valication set.\n\n- ***get_y=parent_label*** - the labels ('y' value) is the name of the 'parent' of each file (i.e., the name of the folder each file is located in which will be *dog* or *cat*.\n\n- ***item_tfms=[Resize(192, method='squish')]*** - resize each image to 192x192 pixles by \"squishing\" (vs. cropping) before training.","metadata":{}},{"cell_type":"code","source":"dls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:00:20.648766Z","iopub.execute_input":"2024-09-16T15:00:20.649504Z","iopub.status.idle":"2024-09-16T15:00:24.956735Z","shell.execute_reply.started":"2024-09-16T15:00:20.649463Z","shell.execute_reply":"2024-09-16T15:00:24.956008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n\n`fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that.","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:00:32.138948Z","iopub.execute_input":"2024-09-16T15:00:32.139261Z","iopub.status.idle":"2024-09-16T15:00:47.04093Z","shell.execute_reply.started":"2024-09-16T15:00:32.139224Z","shell.execute_reply":"2024-09-16T15:00:47.040066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generally when I run this I see 100% accuracy on the validation set (although it might vary a bit from run to run).\n\n\"Fine-tuning\" a model means that we're starting with a model someone else has trained using some other dataset (called the *pretrained model*), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in *imagenet*, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it's important, check out the [free fast.ai course](https://course.fast.ai/).","metadata":{}},{"cell_type":"markdown","source":"## Step 3: Use the model","metadata":{}},{"cell_type":"markdown","source":"Let's see what our model thinks about that animales downloaded at the start:","metadata":{}},{"cell_type":"code","source":"# Test the model using Max\nresult,_,prob = learn.predict(max_image)\ndisplay(max_image.to_thumb(256, 256))\nprint(f\"The model thinks Max is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Lucy's first image\nresult,_,prob = learn.predict(lucy_image)\ndisplay(lucy_image.to_thumb(256, 256))\nprint(f\"The model thinks Lucy a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Lucy's second image\nresult,_,prob = learn.predict(lucy_image2)\ndisplay(lucy_image2.to_thumb(256, 256))\nprint(f\"The model thinks Lucy is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Lucy's third image\nresult,_,prob = learn.predict(lucy_image3)\ndisplay(lucy_image3.to_thumb(256, 256))\nprint(f\"The model thinks Lucy is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Chica\nresult,_,prob = learn.predict(PILImage.create(chica_image))\ndisplay(chica_image.to_thumb(256, 256))\nprint(f\"The model things Chica is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:17.237801Z","iopub.execute_input":"2024-09-16T15:01:17.238561Z","iopub.status.idle":"2024-09-16T15:01:17.782834Z","shell.execute_reply.started":"2024-09-16T15:01:17.238518Z","shell.execute_reply":"2024-09-16T15:01:17.781971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\ninterp.plot_top_losses(5,nrows=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:37.701515Z","iopub.execute_input":"2024-09-16T15:01:37.70231Z","iopub.status.idle":"2024-09-16T15:01:39.510785Z","shell.execute_reply.started":"2024-09-16T15:01:37.70227Z","shell.execute_reply":"2024-09-16T15:01:39.509965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Good job, resnet18. :)\n\nSo, as you see, in the space of a few years, creating computer vision classification models has gone from \"so hard it's a joke\" to \"trivially easy and free\"!\n\nIt's not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including [creating amazing artworks](https://openai.com/dall-e-2/), and [explaining jokes](https://www.datanami.com/2022/04/22/googles-massive-new-language-model-can-explain-jokes/). It's moving so fast that even experts in the field have trouble predicting how it's going to impact society in the coming years.\n\nOne thing is clear -- it's important that we all do our best to understand this technology, because otherwise we'll get left behind!","metadata":{}},{"cell_type":"markdown","source":"Now it's your turn. Click \"Copy & Edit\" and try creating your own image classifier using your own image searches!\n\nIf you enjoyed this, please consider clicking the \"upvote\" button in the top-right -- it's very encouraging to us notebook authors to know when people appreciate our work.","metadata":{}}]}