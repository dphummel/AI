{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9413082,"sourceType":"datasetVersion","datasetId":5716422}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/davidphummel/computer-vision-is-it-a-dog-or-a-cat?scriptVersionId=197067004\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Computer Vision - Is it a dog or a cat?","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nThis is the first Juypter notebook I created while reading chapter 1 of the Fastai course called [Practical Deep Learning](https://course.fast.ai).  Practical Deep Learning is a free course designed for people who have some coding experience and want to learn how to apply deep learning and maching learning to practical problems.  \n\nI believe an understanding of how to program in Python is a requirement to complete this course along the ability to learn mathematical concepts like gradient descent.  \n\nI have spent some time refershing my memory of the NumPy package using the book [NumPy for Data Analysis](https://wesmckinney.com/book/numpy-basics) by Wes McKinney.  The NumPy package is used in the course to load and clean data along with building the models.  \n\nI have also found the need to refresh my memory of some of mathmatical concepts used in deep learning including gradient descent.  I really recommend the videos produced by [StatQuest](https://statquest.org/) on [gradient descent](https://youtu.be/sDv4f4s2SB8?si=SZjknb9ca-nl18ie) and others related to statistics and machine learning.  Josh Starmer created StatQuest to attempt to explain statistics to his former co-wokers.  His vidoes are short, easy to understand, and engaging! \n\nThis Juypter notebook is a copy of Jeremy Howard's notebook called [Is it a bird? Creating a model from your own data](https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data).  I modified Jeremy's notebook to train a model to determine if an image is a dog or a cat.  My family has two portuguese water dogs and 1 three legged cat, so I thought it would be fun to test the model on them.\n\nThe basic steps we'll take are:\n\n1. Use DuckDuckGo to find images of dogs and cats on the Internet.\n2. Fine-tune a pretrained neural network to recognise these two animals.\n3. Run the model on my family pets to determine if it can accuratley identify each animal.","metadata":{}},{"cell_type":"code","source":"# It's a good idea to ensure you're running the latest version of any libraries you need.\n# `!pip install -Uqq <libraries>` upgrades to the latest version of <libraries>\n# You can safely ignore any warnings or errors pip spits out about running as root or incompatibilities\nimport os\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle:\n    !pip install -Uqq fastai fastbook","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-09-16T16:48:27.229414Z","iopub.execute_input":"2024-09-16T16:48:27.230118Z","iopub.status.idle":"2024-09-16T16:48:38.187667Z","shell.execute_reply.started":"2024-09-16T16:48:27.230016Z","shell.execute_reply":"2024-09-16T16:48:38.186722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Download images of dogs and cats\n\nLet's start out by defining a function to search the Internet using DuckDuckGo for a *term* (e.g., \"dog\") which returns a set of URLs to images of the *term*.\n\nNote:  Fastcore is a libruary that adds features to Python inspired by other languages like multiple dispatch from Julia, mixins from Ruby, and currying, binding, and more from Haskell. It also adds some “missing features” and clean up some rough edges in the Python standard library, such as simplifying parallel processing, and bringing ideas from NumPy over to Python’s list type.","metadata":{}},{"cell_type":"code","source":"from fastcore.all import *\nfrom fastbook import search_images_ddg\n\n# search_images will search for a term on the Internet and return a set of URLs which contain the term\ndef search_images(term, max=30):\n  print(f\"Searching for '{term}' using DuckDuckGo\")\n  return search_images_ddg(term, max_images=max)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-16T16:48:47.046539Z","iopub.execute_input":"2024-09-16T16:48:47.0474Z","iopub.status.idle":"2024-09-16T16:48:48.39902Z","shell.execute_reply.started":"2024-09-16T16:48:47.04734Z","shell.execute_reply":"2024-09-16T16:48:48.397996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's download the images of my two dogs, Max and Lucy, and my cat, Chica.  I loaded the images of my pets into a dataset called *My Family Pets* which is attached to this Kaggle Notebook.  I included three images of Lucy in the dataset to test out the model given her unique look.  These images will be used to test the accuracy of the model.","metadata":{}},{"cell_type":"code","source":"from fastdownload import download_url\nfrom fastai.vision.all import *\nfrom PIL import Image, ImageOps\n\n# Download and display the image of Max (see my-family-dogs dataset)\nmax_file = \"../input/my-family-pets/Max.jpg\"\nmax_image = Image.open(max_file)\nmax_image = ImageOps.exif_transpose(max_image)\nmax_image.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:48:51.80031Z","iopub.execute_input":"2024-09-16T16:48:51.800691Z","iopub.status.idle":"2024-09-16T16:48:51.863997Z","shell.execute_reply.started":"2024-09-16T16:48:51.800642Z","shell.execute_reply":"2024-09-16T16:48:51.863238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download and display first image of Lucy (see My Family Pets dataset)\nlucy_file = \"../input/my-family-pets/Lucy.jpg\"\nlucy_image = Image.open(lucy_file)\nlucy_image = ImageOps.exif_transpose(lucy_image)\nlucy_image.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:48:54.318055Z","iopub.execute_input":"2024-09-16T16:48:54.318374Z","iopub.status.idle":"2024-09-16T16:48:54.369369Z","shell.execute_reply.started":"2024-09-16T16:48:54.318322Z","shell.execute_reply":"2024-09-16T16:48:54.368633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download and display the second image of Lucy (see My Family Pets dataset)\nlucy_file2 = \"../input/my-family-pets/Lucy_2.jpg\"\nlucy_image2 = Image.open(lucy_file2)\nlucy_image2 = ImageOps.exif_transpose(lucy_image2)\nlucy_image2.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:48:56.836121Z","iopub.execute_input":"2024-09-16T16:48:56.836839Z","iopub.status.idle":"2024-09-16T16:48:56.878092Z","shell.execute_reply.started":"2024-09-16T16:48:56.836799Z","shell.execute_reply":"2024-09-16T16:48:56.877372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download and display the third image of Lucy (see My Family Pets dataset)\nlucy_file3 = \"../input/my-family-pets/Lucy_3.jpg\"\nlucy_image3 = Image.open(lucy_file3)\nlucy_image3 = ImageOps.exif_transpose(lucy_image3)\nlucy_image3.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:48:58.995903Z","iopub.execute_input":"2024-09-16T16:48:58.99678Z","iopub.status.idle":"2024-09-16T16:48:59.041589Z","shell.execute_reply.started":"2024-09-16T16:48:58.996737Z","shell.execute_reply":"2024-09-16T16:48:59.040776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download and display image of Chica (see My Family Pets dataset)\nchica_file = '../input/my-family-pets/Chica.jpg'\nchica_image = Image.open(chica_file)\nchica_image = ImageOps.exif_transpose(chica_image)\nchica_image.to_thumb(256, 256)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:49:01.596448Z","iopub.execute_input":"2024-09-16T16:49:01.596735Z","iopub.status.idle":"2024-09-16T16:49:01.644235Z","shell.execute_reply.started":"2024-09-16T16:49:01.596704Z","shell.execute_reply":"2024-09-16T16:49:01.643485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's search for and download a set of dog and cat images off the Internet.  We are grabbing a set of images in both categories with different lighting.  The dog images will be stored in \"animals/dog\" and the cat images will be stored in \"animals/cat\".  These images will be used to create the  model training and validation datasets.","metadata":{}},{"cell_type":"code","source":"from time import sleep\n\nterms = 'dog','cat'\npath = Path('animals')\n\nfor term in terms:\n    dest = (path/term)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{term} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{term} sun photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{term} shade photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    resize_images(path/term, max_size=400, dest=path/term)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:49:04.394777Z","iopub.execute_input":"2024-09-16T16:49:04.395678Z","iopub.status.idle":"2024-09-16T16:50:35.20528Z","shell.execute_reply.started":"2024-09-16T16:49:04.395637Z","shell.execute_reply":"2024-09-16T16:50:35.204377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Train the model","metadata":{}},{"cell_type":"markdown","source":"Since some of the download images might not download correctly (which could cause our model training to fail), we will remove them.","metadata":{}},{"cell_type":"code","source":"# Find the images that can't be opened\nfailed = verify_images(get_image_files(path))\n\n# Remove the image files which can't be openend.  The map function will execute the\n# Path.unlink function over the failed images in the failed (L) object.\nfailed.map(Path.unlink)\n\nprint(f\"{len(failed)} images were removed because they could not be verified.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:50:39.245416Z","iopub.execute_input":"2024-09-16T16:50:39.245756Z","iopub.status.idle":"2024-09-16T16:50:39.867977Z","shell.execute_reply.started":"2024-09-16T16:50:39.245713Z","shell.execute_reply":"2024-09-16T16:50:39.867059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To train a model, we will use `DataLoaders`, which is an object that contains a *training set* (the images used to create a model) and a *validation set* (the images used to check the accuracy of a model -- not used during training). In `fastai` we can create that easily using a `DataBlock`, and view sample images from it.\n\nHere what each of the `DataBlock` parameters means:\n\n- ***blocks=(ImageBlock, CategoryBlock)*** - The input to our model are images and the outputs are catogries (in this case either a dog or a cat)\n\n- ***get_items=get_image_files*** - To find all the inputs to the model we run the 'get_image_files' function which results a list of all the image files in the path.\n\n- ***splitter=RandomSplitter(valid_pct=0.2, seed=42)*** - Spilt the data into training and validation sets randomly using 20% of the adta for the valication set.\n\n- ***get_y=parent_label*** - The labels (i.e., 'y' value) is the name of the 'parent' of each file (i.e., the name of the folder each file is located in which will be either *dog* or *cat*).  \n\n- ***item_tfms=[Resize(192, method='squish')]*** - Resize each image to 192x192 pixles by \"squishing\" (vs. cropping) before training.","metadata":{}},{"cell_type":"code","source":"dls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:50:43.010565Z","iopub.execute_input":"2024-09-16T16:50:43.010863Z","iopub.status.idle":"2024-09-16T16:50:45.871456Z","shell.execute_reply.started":"2024-09-16T16:50:43.010831Z","shell.execute_reply":"2024-09-16T16:50:45.870606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we're ready to train the model using the`resnet18` pre-trained model. ResNet-18 is a convolutional neural network that is 18 layers deep. \n\nWe can train this model in a few minutes using a CPU. However, I recommend using a GPU due to its speed in processing cycles.  `fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that.\n\n\"Fine-tuning\" a model means that we're starting with a model someone else has trained using some other dataset (called the *pretrained model*), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in *imagenet*, and widely-used computer vision dataset with images covering 1000 categories.","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:50:52.981785Z","iopub.execute_input":"2024-09-16T16:50:52.982572Z","iopub.status.idle":"2024-09-16T16:51:05.894161Z","shell.execute_reply.started":"2024-09-16T16:50:52.98253Z","shell.execute_reply":"2024-09-16T16:51:05.893159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Use the model","metadata":{}},{"cell_type":"markdown","source":"Let's use the model to predict the type of animal, a dog or cat, for each of my family pets.","metadata":{}},{"cell_type":"code","source":"# Test the model using Max\nresult,_,prob = learn.predict(max_image)\ndisplay(max_image.to_thumb(256, 256))\nprint(f\"The model thinks Max is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Lucy's first image\nresult,_,prob = learn.predict(lucy_image)\ndisplay(lucy_image.to_thumb(256, 256))\nprint(f\"The model thinks Lucy a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Lucy's second image\nresult,_,prob = learn.predict(lucy_image2)\ndisplay(lucy_image2.to_thumb(256, 256))\nprint(f\"The model thinks Lucy is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Lucy's third image\nresult,_,prob = learn.predict(lucy_image3)\ndisplay(lucy_image3.to_thumb(256, 256))\nprint(f\"The model thinks Lucy is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")\n\n# Test the model using Chica\nresult,_,prob = learn.predict(PILImage.create(chica_image))\ndisplay(chica_image.to_thumb(256, 256))\nprint(f\"The model things Chica is a {result}.\")\nprint(f\"Dog Probability: {prob[1]:.4f}\")\nprint(f\"Cat Probability: {prob[0]:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:51:10.918535Z","iopub.execute_input":"2024-09-16T16:51:10.91887Z","iopub.status.idle":"2024-09-16T16:51:11.297046Z","shell.execute_reply.started":"2024-09-16T16:51:10.918833Z","shell.execute_reply":"2024-09-16T16:51:11.296207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's display the confusion matrix which shows the disparty between the correct and incorrect predictions made by the model for each image in the validation dataset.  Let's also display the images with the top losses along with their prediction, actual, loss, and proabilty of the actual category.","metadata":{}},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\ninterp.plot_top_losses(5,nrows=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T16:51:38.333846Z","iopub.execute_input":"2024-09-16T16:51:38.334133Z","iopub.status.idle":"2024-09-16T16:51:40.464451Z","shell.execute_reply.started":"2024-09-16T16:51:38.334101Z","shell.execute_reply":"2024-09-16T16:51:40.463625Z"},"trusted":true},"execution_count":null,"outputs":[]}]}